{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce4e885-4736-4a07-89ba-967bcb4c5885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hemas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwavfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m write\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Configure logging\u001b[39;00m\n\u001b[0;32m     13\u001b[0m logging\u001b[38;5;241m.\u001b[39mbasicConfig(\n\u001b[0;32m     14\u001b[0m     level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     ]\n\u001b[0;32m     20\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers.utils'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import noisereduce as nr\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"transcription.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 1: Audio Recorder\n",
    "class AudioRecorder:\n",
    "    def __init__(self):\n",
    "        self.sample_rate = 16000\n",
    "        self.channels = 1\n",
    "        self.audio_queue = []\n",
    "\n",
    "    def list_devices(self):\n",
    "        \"\"\"Lists all available audio devices.\"\"\"\n",
    "        devices = sd.query_devices()\n",
    "        for i, device in enumerate(devices):\n",
    "            print(f\"{i}: {device['name']}\")\n",
    "\n",
    "    def audio_callback(self, indata, frames, time, status):\n",
    "        self.audio_queue.append(indata.copy())\n",
    "\n",
    "    def record_audio(self, duration=10, device_name=\"default\"):\n",
    "        logging.info(f\"Recording for {duration} seconds at {self.sample_rate} Hz...\")\n",
    "        \n",
    "        # Find the correct device by name\n",
    "        device_id = None\n",
    "        for i, device in enumerate(sd.query_devices()):\n",
    "            if device_name in device['name']:\n",
    "                device_id = i\n",
    "                break\n",
    "\n",
    "        if device_id is None:\n",
    "            raise ValueError(f\"Device '{device_name}' not found\")\n",
    "        \n",
    "        with sd.InputStream(callback=self.audio_callback, channels=self.channels, samplerate=self.sample_rate, device=device_id):\n",
    "            sd.sleep(int(duration * 1000))\n",
    "        \n",
    "        # Combine all the chunks and save as a single WAV file\n",
    "        combined_audio = np.concatenate(self.audio_queue, axis=0)\n",
    "        raw_audio_folder = \"raw_audio\"\n",
    "        os.makedirs(raw_audio_folder, exist_ok=True)\n",
    "        raw_file_path = os.path.join(raw_audio_folder, \"raw_audio_combined.wav\")\n",
    "        write(raw_file_path, self.sample_rate, combined_audio.astype(np.float32))\n",
    "        logging.info(f\"Saved raw audio to {raw_file_path}\")\n",
    "        return raw_file_path\n",
    "\n",
    "# Step 2: Audio Processing\n",
    "class AudioProcessor:\n",
    "    def __init__(self, output_dir=\"cleaned_audio\"):\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def clean_audio(self, raw_file_path):\n",
    "        logging.info(f\"Cleaning audio: {raw_file_path}\")\n",
    "        waveform, sample_rate = torchaudio.load(raw_file_path)\n",
    "\n",
    "        # Convert to mono\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "        # Apply noise reduction\n",
    "        waveform_np = waveform.numpy()\n",
    "        reduced_noise_waveform = nr.reduce_noise(y=waveform_np, sr=sample_rate)\n",
    "\n",
    "        # Convert back to tensor\n",
    "        cleaned_waveform_tensor = torch.tensor(reduced_noise_waveform, dtype=torch.float32)\n",
    "\n",
    "        # Save cleaned audio\n",
    "        cleaned_file_path = os.path.join(self.output_dir, \"cleaned_audio.wav\")\n",
    "        torchaudio.save(cleaned_file_path, cleaned_waveform_tensor, sample_rate)\n",
    "        logging.info(f\"Saved cleaned audio to {cleaned_file_path}\")\n",
    "        return cleaned_file_path\n",
    "\n",
    "# Step 3: Speech-to-Text Transcription\n",
    "class SpeechToTextTranscriber:\n",
    "    def __init__(self):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        torch_dtype = torch.float32\n",
    "        model_id = \"distil-whisper/distil-large-v3\"\n",
    "\n",
    "        # Load the Whisper model and processor\n",
    "        self.model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "            model_id, torch_dtype=torch_dtype, use_safetensors=True\n",
    "        ).to(device)\n",
    "        self.processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "        # Create a speech recognition pipeline\n",
    "        self.pipe = pipeline(\n",
    "            \"automatic-speech-recognition\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.processor.tokenizer,\n",
    "            feature_extractor=self.processor.feature_extractor,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "    def transcribe(self, cleaned_audio_file):\n",
    "        logging.info(f\"Transcribing {cleaned_audio_file}...\")\n",
    "        result = self.pipe(cleaned_audio_file, return_timestamps=\"word\")\n",
    "        text = result['text']\n",
    "        logging.info(f\"Transcription: {text}\")\n",
    "        return text\n",
    "\n",
    "# Main execution function\n",
    "def main():\n",
    "    # Step 1: Record audio\n",
    "    recorder = AudioRecorder()\n",
    "\n",
    "    # Call the list of devices to select the right device\n",
    "    #recorder.list_devices()\n",
    "\n",
    "    # Specify the correct device name found in the list\n",
    "    raw_file_path = recorder.record_audio(duration=10, device_name=\"Microphone Array (Intel® Smart Sound Technology for Digital Microphones)\")\n",
    "\n",
    "    # Step 2: Clean the recorded audio\n",
    "    audio_processor = AudioProcessor()\n",
    "    cleaned_file_path = audio_processor.clean_audio(raw_file_path)\n",
    "\n",
    "    # Step 3: Transcribe the cleaned audio\n",
    "    transcriber = SpeechToTextTranscriber()\n",
    "    transcription = transcriber.transcribe(cleaned_file_path)\n",
    "\n",
    "    logging.info(f\"Final Transcription: {transcription}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f272be76-630b-4f31-b91c-d607e5561bfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3592654251.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install transformers\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
