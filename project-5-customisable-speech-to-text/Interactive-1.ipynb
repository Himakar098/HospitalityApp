{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to Python 3.12.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7187d55d-51cc-4e7d-8b24-0ae3732b259d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hemas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hemas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\noisereduce\\spectralgate\\nonstationary.py:70: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_mult_above_thresh = (abs_sig_stft - sig_stft_smooth) / sig_stft_smooth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Couldn't find appropriate backend to handle uri temp_audio.wav and format wav.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m             ipd\u001b[38;5;241m.\u001b[39mdisplay(ipd\u001b[38;5;241m.\u001b[39mAudio(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_audio.wav\u001b[39m\u001b[38;5;124m'\u001b[39m, rate\u001b[38;5;241m=\u001b[39msample_rate))\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Run the function to stream and transcribe\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m \u001b[43mstream_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Stream for 10 seconds\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 80\u001b[0m, in \u001b[0;36mstream_audio\u001b[1;34m(duration)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Ensure audio is saved in a valid format for STT (16-bit PCM WAV)\u001b[39;00m\n\u001b[0;32m     79\u001b[0m processed_audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(processed_audio, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp_audio.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_audio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Perform STT on the processed audio\u001b[39;00m\n\u001b[0;32m     83\u001b[0m transcription \u001b[38;5;241m=\u001b[39m transcribe_audio(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_audio.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchaudio\\_backend\\utils.py:312\u001b[0m, in \u001b[0;36mget_save_func.<locals>.save\u001b[1;34m(uri, src, sample_rate, channels_first, format, encoding, bits_per_sample, buffer_size, backend, compression)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\n\u001b[0;32m    225\u001b[0m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    226\u001b[0m     src: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     compression: Optional[Union[CodecConfig, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    235\u001b[0m ):\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save audio data to file.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    310\u001b[0m \n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 312\u001b[0m     backend \u001b[38;5;241m=\u001b[39m \u001b[43mdispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msave(\n\u001b[0;32m    314\u001b[0m         uri, src, sample_rate, channels_first, \u001b[38;5;28mformat\u001b[39m, encoding, bits_per_sample, buffer_size, compression\n\u001b[0;32m    315\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchaudio\\_backend\\utils.py:222\u001b[0m, in \u001b[0;36mget_save_func.<locals>.dispatcher\u001b[1;34m(uri, format, backend_name)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcan_encode(uri, \u001b[38;5;28mformat\u001b[39m):\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m backend\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find appropriate backend to handle uri \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Couldn't find appropriate backend to handle uri temp_audio.wav and format wav."
     ]
    }
   ],
   "source": [
    "import sounddevice as sd # type: ignore\n",
    "import numpy as np\n",
    "import queue\n",
    "import threading\n",
    "import torchaudio # type: ignore\n",
    "import noisereduce as nr\n",
    "import speech_recognition as sr\n",
    "from scipy.signal import butter, lfilter\n",
    "import torch\n",
    "import IPython.display as ipd  # For audio display in Jupyter\n",
    "\n",
    "# Set up a queue for live audio streaming\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "# Audio stream parameters\n",
    "sample_rate = 16000\n",
    "block_size = 1024  # Number of frames per block\n",
    "\n",
    "# Preprocessing functions\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def process_audio(audio_chunk, sample_rate=16000, low_freq=300, high_freq=3400):\n",
    "    # Convert audio to numpy array\n",
    "    audio_chunk_np = np.array(audio_chunk, dtype=np.float32)\n",
    "    \n",
    "    # Noise reduction\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio_chunk_np, sr=sample_rate)\n",
    "    \n",
    "    # Apply band-pass filtering to isolate speech\n",
    "    filtered_audio = bandpass_filter(reduced_noise_audio, low_freq, high_freq, sample_rate)\n",
    "    \n",
    "    return filtered_audio\n",
    "\n",
    "# STT transcription using speech_recognition\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def transcribe_audio(audio_data_path):\n",
    "    try:\n",
    "        # Use speech_recognition to recognize audio\n",
    "        with sr.AudioFile(audio_data_path) as source:\n",
    "            audio = recognizer.record(source)\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "# Callback function to handle audio blocks\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"This function is called for each audio block in the stream\"\"\"\n",
    "    if status:\n",
    "        print(status, flush=True)\n",
    "    audio_queue.put(indata.copy())  # Add the recorded block to the queue\n",
    "\n",
    "# Function to stream and process audio for a fixed time (e.g., 10 seconds)\n",
    "def stream_audio(duration=10):\n",
    "    with sd.InputStream(samplerate=sample_rate, channels=1, callback=audio_callback, blocksize=block_size):\n",
    "        print(f\"Recording for {duration} seconds...\")\n",
    "        sd.sleep(duration * 1000)  # Record for the specified duration\n",
    "\n",
    "        # Get audio data from the queue and process it\n",
    "        while not audio_queue.empty():\n",
    "            audio_chunk = audio_queue.get()\n",
    "\n",
    "            # Preprocess audio chunk\n",
    "            processed_audio = process_audio(audio_chunk, sample_rate=sample_rate)\n",
    "\n",
    "            # Ensure audio is saved in a valid format for STT (16-bit PCM WAV)\n",
    "            processed_audio = torch.tensor(processed_audio, dtype=torch.float32).unsqueeze(0)\n",
    "            torchaudio.save('temp_audio.wav', processed_audio, sample_rate, format=\"wav\")\n",
    "\n",
    "            # Perform STT on the processed audio\n",
    "            transcription = transcribe_audio('temp_audio.wav')\n",
    "            if transcription:\n",
    "                print(f\"Transcription: {transcription}\")\n",
    "\n",
    "            # Play the processed audio in Jupyter Notebook\n",
    "            ipd.display(ipd.Audio('temp_audio.wav', rate=sample_rate))\n",
    "\n",
    "# Run the function to stream and transcribe\n",
    "stream_audio(duration=10)  # Stream for 10 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
